{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e1fce-d1e3-4322-a81d-86d8ae2da0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from faker import Faker\n",
    "\n",
    "# Create a Faker instance\n",
    "fake = Faker()\n",
    "\n",
    "# Define the number of rows you want in your dataset\n",
    "user_num_rows = 1000  # You can change this number as needed\n",
    "\n",
    "# Generate random data\n",
    "data = {\n",
    "     'userId': list(range(1, user_num_rows + 1)),\n",
    "    'userName': [fake.name() for _ in range(user_num_rows)],\n",
    "    'age': [random.randint(18, 65) for _ in range(user_num_rows)],\n",
    "    'gender': [random.choice(['M', 'F']) for _ in range(user_num_rows)],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('random_user_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8030e62-3f5f-4922-a378-1f929c5dfff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of rows you want in your dataset\n",
    "service_num_rows = 1500  # You can change this number as needed\n",
    "\n",
    "# Generate random data for the \"service\" table\n",
    "data = {\n",
    "    'serviceId': list(range(1, service_num_rows + 1)),\n",
    "    'serviceName': [fake.word().capitalize() for _ in range(service_num_rows)],\n",
    "}\n",
    "\n",
    "# Create a DataFrame for the \"service\" table\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('random_service_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14f0a77-84d9-431e-82c6-2ae7065026e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of rows you want in your \"ratings\" dataset\n",
    "ratings_num_rows = 100000  # You can change this number as needed\n",
    "\n",
    "# Create a DataFrame for the \"ratings\" table\n",
    "ratings_data = {\n",
    "    'userId': [random.randint(1, user_num_rows) for _ in range(ratings_num_rows)],\n",
    "    'serviceId': [random.randint(1, service_num_rows) for _ in range(ratings_num_rows)],\n",
    "    'rating': [random.randint(1, 5) for _ in range(ratings_num_rows)],\n",
    "}\n",
    "\n",
    "ratings_df = pd.DataFrame(ratings_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "ratings_df.to_csv('random_ratings_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f94c7e2-fc43-4f76-a65c-33598198c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from pyspark.sql.functions import col, collect_list,pow,sqrt,abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a85fcf-d97e-4721-b097-1845141a6f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/06 15:48:02 WARN Utils: Your hostname, razin-ThinkPad resolves to a loopback address: 127.0.1.1; using 10.10.20.157 instead (on interface wlp0s20f3)\n",
      "23/09/06 15:48:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/06 15:48:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ServiceRecommendation\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef20812b-6280-4aa4-84c4-d3fdb34f37cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the user data CSV file into a DataFrame\n",
    "user_df = spark.read.csv('random_user_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Read the service data CSV file into a DataFrame\n",
    "service_df = spark.read.csv('random_service_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Read the ratings data CSV file into a DataFrame\n",
    "ratings_df = spark.read.csv('random_ratings_data.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9528566f-2176-4914-99a5-83b3bca5540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+---+------+\n",
      "|userId|       userName|age|gender|\n",
      "+------+---------------+---+------+\n",
      "|     1|     Tammy Bond| 27|     M|\n",
      "|     2|   Anthony Ward| 46|     M|\n",
      "|     3|      Paul Ware| 39|     F|\n",
      "|     4|   Dustin Smith| 53|     F|\n",
      "|     5|   Sean Mcgrath| 62|     M|\n",
      "|     6|   Peter Warren| 43|     F|\n",
      "|     7|      Seth Hall| 23|     F|\n",
      "|     8|    Seth Krause| 61|     F|\n",
      "|     9|  Marco Andrews| 22|     F|\n",
      "|    10|    Collin Huff| 50|     F|\n",
      "|    11|   Jennifer Lam| 33|     M|\n",
      "|    12|     Lori Brown| 45|     F|\n",
      "|    13|   Sylvia Klein| 40|     M|\n",
      "|    14|    Joshua Cook| 28|     M|\n",
      "|    15|  Anthony Ellis| 58|     F|\n",
      "|    16|    Kelsey Hahn| 28|     F|\n",
      "|    17|Zachary Elliott| 45|     F|\n",
      "|    18| Angela Stewart| 21|     F|\n",
      "|    19|   Keith Hodges| 34|     M|\n",
      "|    20| Melissa Adkins| 63|     M|\n",
      "+------+---------------+---+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+-----------+\n",
      "|serviceId|serviceName|\n",
      "+---------+-----------+\n",
      "|        1|      Court|\n",
      "|        2|        But|\n",
      "|        3|        And|\n",
      "|        4|      Least|\n",
      "|        5|     Modern|\n",
      "|        6|      Close|\n",
      "|        7|       Live|\n",
      "|        8| Investment|\n",
      "|        9|   Consider|\n",
      "|       10|     Nation|\n",
      "|       11|        Get|\n",
      "|       12|     Speech|\n",
      "|       13|     Entire|\n",
      "|       14|      Exist|\n",
      "|       15|    Manager|\n",
      "|       16|     Though|\n",
      "|       17|         Or|\n",
      "|       18|       Pick|\n",
      "|       19|     Reduce|\n",
      "|       20|      Trial|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+---------+------+\n",
      "|userId|serviceId|rating|\n",
      "+------+---------+------+\n",
      "|   706|      508|     1|\n",
      "|   429|      888|     4|\n",
      "|   329|      911|     2|\n",
      "|    60|      838|     4|\n",
      "|   447|     1396|     3|\n",
      "|   680|      817|     5|\n",
      "|   717|     1031|     3|\n",
      "|   718|      807|     4|\n",
      "|   165|     1206|     3|\n",
      "|   588|      908|     4|\n",
      "|   483|      696|     3|\n",
      "|   537|     1406|     4|\n",
      "|   227|      566|     3|\n",
      "|    42|      174|     5|\n",
      "|   817|      651|     3|\n",
      "|   606|      986|     5|\n",
      "|   630|     1339|     3|\n",
      "|   199|     1179|     4|\n",
      "|   230|      455|     2|\n",
      "|   401|     1167|     5|\n",
      "+------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_df.show()\n",
    "service_df.show()\n",
    "ratings_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ec68d7-ef72-4c26-9ce8-5904e24a847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+---+\n",
      "|userId|serviceId|rating|gender|age|\n",
      "+------+---------+------+------+---+\n",
      "|   706|      508|     1|     F| 21|\n",
      "|   429|      888|     4|     M| 40|\n",
      "|   329|      911|     2|     F| 40|\n",
      "|    60|      838|     4|     M| 37|\n",
      "|   447|     1396|     3|     F| 37|\n",
      "|   680|      817|     5|     F| 59|\n",
      "|   717|     1031|     3|     F| 22|\n",
      "|   718|      807|     4|     M| 39|\n",
      "|   165|     1206|     3|     F| 51|\n",
      "|   588|      908|     4|     F| 57|\n",
      "|   483|      696|     3|     M| 27|\n",
      "|   537|     1406|     4|     F| 62|\n",
      "|   227|      566|     3|     M| 41|\n",
      "|    42|      174|     5|     M| 37|\n",
      "|   817|      651|     3|     M| 59|\n",
      "|   606|      986|     5|     F| 65|\n",
      "|   630|     1339|     3|     F| 25|\n",
      "|   199|     1179|     4|     F| 27|\n",
      "|   230|      455|     2|     M| 65|\n",
      "|   401|     1167|     5|     M| 24|\n",
      "+------+---------+------+------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join ratings, users, and movies dataframes\n",
    "joined_df = ratings_df.join(user_df.select(\"userId\", \"gender\", \"age\"), on=\"userId\", how=\"inner\")\n",
    "joined_df = joined_df.filter(col(\"serviceId\").isNotNull())\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484c9ac4-2932-4b1b-87e8-4e858d01e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define gender, age, and occupation filters\n",
    "#gender_filter = \"F\"\n",
    "#age_filter_min = 18\n",
    "#age_filter_max = 24\n",
    "#occupation_filter = \"writer\"\n",
    "\n",
    "# Filter data based on gender, age, and occupation\n",
    "#filtered_df = joined_df.filter(\n",
    "#    (col(\"gender\") == gender_filter) &\n",
    "#    (col(\"age\") <= age_filter_max) &\n",
    "#    (col(\"age\") >= age_filter_min)\n",
    "#)\n",
    "\n",
    "#filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df72095-02a0-4e04-850e-df501e63a980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 75018\n",
      "N test 24982\n"
     ]
    }
   ],
   "source": [
    "train, test = spark_random_split(joined_df, ratio=0.75, seed=123)\n",
    "print(\"N train\", train.cache().count())\n",
    "print(\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9135e7e-06d7-47c1-a98b-eb306caebbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_USER = \"userId\"\n",
    "COL_ITEM = \"serviceId\"\n",
    "COL_RATING = \"rating\"\n",
    "\n",
    "# Train the ALS model\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    userCol=COL_USER, itemCol=COL_ITEM, ratingCol=COL_RATING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb95e1e-4a48-4b1d-b155-3983d3d59fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/06 15:48:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/09/06 15:48:11 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 3.9263531800024793 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as train_time:\n",
    "    model = als.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bd62d00-2c54-4a0b-b16a-be4949fd4139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:================================================>    (182 + 9) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 10.82458040399797 seconds for prediction.\n",
      "+------+---------+----------+\n",
      "|userId|serviceId|prediction|\n",
      "+------+---------+----------+\n",
      "|     1|      587| 2.1268969|\n",
      "|     1|      869| 3.4434083|\n",
      "|     1|     1208| 5.3751073|\n",
      "|     1|     1348| 3.7945688|\n",
      "|     1|     1357| 1.9100304|\n",
      "|     2|       80| 1.9099348|\n",
      "|     2|      472| 0.7585122|\n",
      "|     2|      582| 3.9361854|\n",
      "|     2|      838| 1.4924681|\n",
      "|     2|      975| 0.8307763|\n",
      "|     2|     1260| 2.3388429|\n",
      "|     2|     1325|  1.615089|\n",
      "|     2|     1381| 4.2416854|\n",
      "|     3|       22| 2.8967817|\n",
      "|     3|       57| 2.5475547|\n",
      "|     3|       89| 2.0668979|\n",
      "|     3|      367| 3.5179217|\n",
      "|     3|     1091| 2.0814824|\n",
      "|     3|     1167| 4.2013016|\n",
      "|     3|     1499| 3.7177808|\n",
      "+------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    # Get the cross join of all user-item pairs and score them.\n",
    "    users = train.select(COL_USER).distinct()\n",
    "    items = train.select(COL_ITEM).distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "\n",
    "        # Remove seen items.\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (col(\"pred.\" + COL_USER) == col(\"train.\" + COL_USER)) &\n",
    "        (col(\"pred.\" + COL_ITEM) == col(\"train.\" + COL_ITEM)),\n",
    "        how='outer'\n",
    "    )\n",
    "    \n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[f\"train.{COL_RATING}\"].isNull()) \\\n",
    "        .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "    # In Spark, transformations are lazy evaluation\n",
    "    # Use an action to force execute and measure the test time \n",
    "    top_all.cache().count()\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))\n",
    "top_all.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab2df5f-d182-42b5-9b29-95b9ef8877cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 595:===================================>                 (133 + 8) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+---+----------+\n",
      "|userId|serviceId|rating|gender|age|prediction|\n",
      "+------+---------+------+------+---+----------+\n",
      "|   633|      148|     3|     F| 41| 2.2394624|\n",
      "|   633|      148|     3|     F| 41| 2.2394624|\n",
      "|   101|      148|     5|     F| 49| 4.6426487|\n",
      "|   346|      148|     1|     F| 21|  4.050703|\n",
      "|   519|      148|     2|     F| 25|  5.027049|\n",
      "|   696|      148|     5|     M| 57| 2.4729042|\n",
      "|   386|      148|     3|     M| 46|  2.767638|\n",
      "|   435|      148|     2|     M| 51| 3.2766035|\n",
      "|   572|      148|     2|     F| 59| 2.3134737|\n",
      "|    64|      148|     1|     M| 33|   3.49406|\n",
      "|   886|      148|     3|     F| 32| 4.3128533|\n",
      "|   712|      148|     1|     M| 41| 2.6545491|\n",
      "|   243|      463|     1|     M| 64| 1.9968162|\n",
      "|   513|      463|     1|     M| 48| 3.9708512|\n",
      "|   597|      463|     5|     M| 62| 3.8436112|\n",
      "|   368|      463|     5|     M| 40| 2.9039812|\n",
      "|   388|      463|     1|     F| 58| 2.3138795|\n",
      "|   409|      463|     1|     F| 56|  3.122368|\n",
      "|   578|      463|     4|     M| 38| 3.6418347|\n",
      "|   333|      463|     1|     M| 54| 3.8441772|\n",
      "+------+---------+------+------+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate predicted ratings.\n",
    "prediction = model.transform(test)\n",
    "prediction.cache().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e260cd2a-9a0e-4db5-afc7-c8c11580bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+------+------+---+----------+----------+\n",
      "|userId|serviceId|rating|gender|age|prediction|  accuracy|\n",
      "+------+---------+------+------+---+----------+----------+\n",
      "|   633|      148|     3|     F| 41| 2.2394624| 0.7605376|\n",
      "|   633|      148|     3|     F| 41| 2.2394624| 0.7605376|\n",
      "|   101|      148|     5|     F| 49| 4.6426487| 0.3573513|\n",
      "|   346|      148|     1|     F| 21|  4.050703|  3.050703|\n",
      "|   519|      148|     2|     F| 25|  5.027049|  3.027049|\n",
      "|   696|      148|     5|     M| 57| 2.4729042| 2.5270958|\n",
      "|   386|      148|     3|     M| 46|  2.767638|0.23236203|\n",
      "|   435|      148|     2|     M| 51| 3.2766035| 1.2766035|\n",
      "|   572|      148|     2|     F| 59| 2.3134737| 0.3134737|\n",
      "|    64|      148|     1|     M| 33|   3.49406|   2.49406|\n",
      "|   886|      148|     3|     F| 32| 4.3128533| 1.3128533|\n",
      "|   712|      148|     1|     M| 41| 2.6545491| 1.6545491|\n",
      "|   243|      463|     1|     M| 64| 1.9968162|0.99681616|\n",
      "|   513|      463|     1|     M| 48| 3.9708512| 2.9708512|\n",
      "|   597|      463|     5|     M| 62| 3.8436112| 1.1563888|\n",
      "|   368|      463|     5|     M| 40| 2.9039812| 2.0960188|\n",
      "|   388|      463|     1|     F| 58| 2.3138795| 1.3138795|\n",
      "|   409|      463|     1|     F| 56|  3.122368|  2.122368|\n",
      "|   578|      463|     4|     M| 38| 3.6418347|0.35816526|\n",
      "|   333|      463|     1|     M| 54| 3.8441772| 2.8441772|\n",
      "+------+---------+------+------+---+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum ,mean,avg\n",
    "prediction_with_accuracy = prediction.withColumn(\"accuracy\", abs(col(\"rating\") - col(\"prediction\")))\n",
    "\n",
    "\n",
    "# Show the DataFrame with the \"accuracy\" column\n",
    "prediction_with_accuracy.show()\n",
    "\n",
    "#This code calculates the MAE between the \"rating\" and \"prediction\" columns and then converts it into accuracy by subtracting it from 1.0 and multiplying by 100 to get a percentage value. It will print both the MAE and accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afbf88f5-32b8-4c96-a5d4-04885c2468df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage_accuracy: 71.27\n"
     ]
    }
   ],
   "source": [
    "overall_accuracy = prediction_with_accuracy.agg({\"accuracy\": \"mean\"}).collect()[0][0]\n",
    "percentage_accuracy = (1-(overall_accuracy/5))*100\n",
    "# Show the overall accuracy\n",
    "print(f\"Percentage_accuracy: {percentage_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a701580-8ee5-4d35-a0a1-a991bd386e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup Spark instance\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
